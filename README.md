# Gradient Gradient

A simple classification using linear regression via the gradient descent algorithm. 

![linear_regression_gradient](https://cloud.githubusercontent.com/assets/25164326/25768732/f06bfbc4-31d7-11e7-953e-461947779ec1.png)

### Figure-1:

The two differential equations above in Figure-1 is the partial derivation of the cost function with respect to the gradient of the line m, and the the constant b of the line. These equations are fundamental in gradient descent as the rate of change of the cost function with respect to both m and b allows us to plot the line that best fits through our data points. 


![without-linear-line](https://cloud.githubusercontent.com/assets/25164326/25768997/52dfddac-31dd-11e7-8d3b-067b53e07da6.png)

### Figure-2:

The graph diagram above in Figure-2 shows the plots of the x and y values from the data.csv file. Our goal is to find the line of best fit using gradient descent, a line that can go straight through the curve which would find a relationship between the x and the y values.


![with-linear-line](https://cloud.githubusercontent.com/assets/25164326/25768994/50d31b0a-31dd-11e7-9a19-b3f840de1bf4.png)

### Figure-3:
                                   
The graph diagram above in Figure-3 shows a linear line going through the data points, showing us what we want to achieve!
